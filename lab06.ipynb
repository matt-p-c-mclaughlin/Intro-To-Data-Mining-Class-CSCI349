{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab06 - Preprocessing I\n",
    "#### Name: Matt McLaughlin \n",
    "#### Class: CSCI 349 - Intro to Data Mining \n",
    "#### Semester: 2020SP \n",
    "#### Instructor: Brian King"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) [P] Use pandas to read in your CSV data file you downloaded above, which you should have placed in your\n",
    "data directory. Call the data frame df_temps. Read in the entire dataset, however, peek at the dataset\n",
    "first. You'll notice 16 rows of metadata. Ignore the first 16 rows (HINT: Use the skiprows= option!)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temps = pd.read_csv(filepath_or_buffer=\"../data/faa_hourly-KIPT_20000101-20191231_raw.csv\", skiprows=16)\n",
    "#df_temps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: BE SURE TO LOOK AT YOUR ACTUAL DATA BEFORE TRYING TO READ IN A RAW DATASET! JUST BECAUSE\n",
    "A DATASET HAS A .CSV EXTENSION DOES NOT MEAN THAT YOU CAN RELY ON EVERY ROW BEING A PROPERLY\n",
    "FORMATTED ROW! For instance, notice that the header row is scattered throughout your data! Notice that\n",
    "you have some extra columns at the end that are consistently empty! The inexperienced are tempted to\n",
    "manually edit the file to make it easy to read. NO. WRONG! BAD DATA SCIENTIST! Write your Python cleaning\n",
    "code to always work with raw, uncleaned data. Why? In practice, your data file may be huge. You may need to\n",
    "repeatedly grab fresh data, that will only have the same issues. Do you really want to repeat your manual\n",
    "editing silliness every time you have a fresh file? No! It may take a bit more work up front, but ALWAYS strive\n",
    "to write code to preprocess every aspect of your data file! It will always save you work later!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Report the general structure of the data frame using df_temps.info(). You should notice that almost\n",
    "every variable was read in as a plan object data type. You have a lot of work to do!\n",
    "Your result should look as follows:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 181914 entries, 0 to 181913\n",
      "Data columns (total 14 columns):\n",
      "Date/Time (GMT)                  181914 non-null object\n",
      "Number of Observations (n/a)     181914 non-null object\n",
      "Average Temp (F)                 180915 non-null object\n",
      "Max Temp (F)                     180915 non-null object\n",
      "Min Temp (F)                     180915 non-null object\n",
      "Average Dewpoint Temp (F)        180809 non-null object\n",
      "1 Hour Precip (in)               37596 non-null object\n",
      "Max Wind Gust (mph)              32206 non-null object\n",
      "Average Relative Humidity (%)    177416 non-null object\n",
      "Average Wind Speed (mph)         181372 non-null object\n",
      "Average Station Pressure (mb)    181636 non-null object\n",
      "Average Wind Direction (deg)     149252 non-null object\n",
      "Max Wind Speed (mph)             181372 non-null object\n",
      "Unnamed: 13                      0 non-null float64\n",
      "dtypes: float64(1), object(13)\n",
      "memory usage: 19.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_temps.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is a pretty good dataset with lots of real problems! It gives you a chance to understand how important it is to\n",
    "select the smallest, yet most accurate data type for every variable. This is particularly true with respect to your\n",
    "memory footprint. With enormous data involving millions of records, you often need to perform various paging\n",
    "exercises to load in chunks of data into memory, substantially slowing down the machine learning methods. In\n",
    "other words, the more data you can fit in memory, the better!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) [P] Read about the memory_usage() method of pandas data frames. Then, report the total memory in\n",
    "bytes for each variable of df_temps. Set the parameter deep=True, to get the most accurate assessment\n",
    "of your total memory usage. (NOTE – this could take a bit of time to return an answer.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index                                 128\n",
       "Date/Time (GMT)                  13790816\n",
       "Number of Observations (n/a)     11477885\n",
       "Average Temp (F)                 11342670\n",
       "Max Temp (F)                     11308038\n",
       "Min Temp (F)                     11308017\n",
       "Average Dewpoint Temp (F)        11411051\n",
       "1 Hour Precip (in)                7032800\n",
       "Max Wind Gust (mph)               6907372\n",
       "Average Relative Humidity (%)    11354487\n",
       "Average Wind Speed (mph)         11291210\n",
       "Average Station Pressure (mb)    11647992\n",
       "Average Wind Direction (deg)     10569351\n",
       "Max Wind Speed (mph)             11259415\n",
       "Unnamed: 13                       1455312\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#http://lira.no-ip.org:8080/doc/python-pandas-doc/html/generated/pandas.DataFrame.memory_usage.html#pandas.DataFrame.memory_usage\n",
    "mem_use = df_temps.memory_usage(deep=True)\n",
    "mem_use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) [P] Report the total memory required for the data frame in MB. (Just sum the previous answer.) You should\n",
    "get an answer showing over a hundred megabytes! Also, store the total as a variable called\n",
    "original_memory. We're going to compare memory after we're done.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original memory is 135.571 MB (rounded)\n"
     ]
    }
   ],
   "source": [
    "original_memory = sum(mem_use) / 1048576\n",
    "print(\"Original memory is \" + \"{:.3f}\".format(original_memory) + \" MB (rounded)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5) [P] Remember those extra column header lines that appeared throughout the entire CSV file? You need to get\n",
    "rid of those. Write the code to eliminated those from df_temps. (This is tricky. Think about it... you are\n",
    "selecting the data that does NOT have columns[0] as the first value in the observation!)\n",
    "HINT – At this point, you should have 173252 observations.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173252"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I don't know why, but it took me an incredibly long time to get this. Just wasn't clicking.\n",
    "fc = df_temps.columns[0]\n",
    "df_temps = df_temps[df_temps[fc] != fc]\n",
    "len(df_temps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6) [M-P] Examine the last entry of your index (i.e. df_temps.index[-1]). Then, show the number of\n",
    "observations in df_temps. These are unequal. Why?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181913"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temps.index[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173252"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temps.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Because while we have been removing rows from the dataframe, we haven't been relabeling/renumbering the indexes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7) When you permanently delete observations, it's usually a good idea to reset your index, especially if the index\n",
    "is nothing more than a unique number to each observations. Reindex your data, and show that the new index\n",
    "is indeed reset. (There are many ways to do this. I suggest using reset_index(). There is no need to\n",
    "retain the original index, so drop=True is fine.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temps = df_temps.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8) You have a rather annoying extra column that was read in in the last column position. (Look closely at the\n",
    "output of `describe()` above!) You should always confirm that it's garbage before deleting it. Write the\n",
    "single line of code that reports the count of valid values in the last column (HINT: count())**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temps.count()[\"Unnamed: 13\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9) Drop that last column from df_temps.\n",
    "I cannot emphasize this enough – you will get the most out of your data when you take the time to set up the\n",
    "most accurate type for each variable. Currently, the type of every variable is object. However, notice that in\n",
    "your raw data file, EVERY variable is a number except the first variable, which is a date. Dates are COMMON in\n",
    "data, and it is important that you represent dates as actual date types! We'll deal with that shortly. Let's\n",
    "continue cleaning this up.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temps = df_temps.iloc[:,0:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10) [P] Convert all numeric data to actual numeric data types. You'll need to look up how to do this. (HINT:\n",
    "pd.to_numeric() is your friend.) Leave the NaN fields alone! The fact that they are missing is\n",
    "IMPORTANT! And, leave the date/time variable in the first column alone.\n",
    "You should output the shape of your data, and show info() to show every variable is a floating point\n",
    "number except the date/time field in the first column, which should still be of type object.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert numerica data to numeric data types\n",
    "#df_temps = df_temps.iloc[1:,:].apply(pd.to_numeric)\n",
    "#Not sure if theres a difference between the above and \n",
    "#df_temps = df_temps.apply(pd.to_numeric)\n",
    "\n",
    "#Problem with all above is they don't pass parameters to pd.to_numeric(), causes trouble in #12\n",
    "for i in range(1, len(df_temps.columns)):\n",
    "    df_temps.iloc[:,i] = pd.to_numeric(arg=df_temps.iloc[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173252, 12)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show shape()\n",
    "df_temps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 173252 entries, 0 to 173251\n",
      "Data columns (total 12 columns):\n",
      "Date/Time (GMT)                  173252 non-null object\n",
      "Number of Observations (n/a)     173252 non-null int64\n",
      "Average Temp (F)                 172253 non-null float64\n",
      "Max Temp (F)                     172253 non-null float64\n",
      "Min Temp (F)                     172253 non-null float64\n",
      "Average Dewpoint Temp (F)        172147 non-null float64\n",
      "1 Hour Precip (in)               28934 non-null float64\n",
      "Max Wind Gust (mph)              23544 non-null float64\n",
      "Average Relative Humidity (%)    168754 non-null float64\n",
      "Average Wind Speed (mph)         172710 non-null float64\n",
      "Average Station Pressure (mb)    172974 non-null float64\n",
      "Average Wind Direction (deg)     140590 non-null float64\n",
      "dtypes: float64(10), int64(1), object(1)\n",
      "memory usage: 15.9+ MB\n"
     ]
    }
   ],
   "source": [
    "#Show info() to show type of variables\n",
    "df_temps.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**11) [P] How much did our memory footprint improve? (Show the total memory usage using deep=True). Report\n",
    "the total memory usage in MB, and report the percentage improvement.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index                                 128\n",
       "Date/Time (GMT)                  13167152\n",
       "Number of Observations (n/a)      1386016\n",
       "Average Temp (F)                  1386016\n",
       "Max Temp (F)                      1386016\n",
       "Min Temp (F)                      1386016\n",
       "Average Dewpoint Temp (F)         1386016\n",
       "1 Hour Precip (in)                1386016\n",
       "Max Wind Gust (mph)               1386016\n",
       "Average Relative Humidity (%)     1386016\n",
       "Average Wind Speed (mph)          1386016\n",
       "Average Station Pressure (mb)     1386016\n",
       "Average Wind Direction (deg)      1386016\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem_use2 = df_temps.memory_usage(deep=True)\n",
    "mem_use2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New memory is 27.097 MB (rounded)\n",
      "Improvment over original: 0.8001% (rounded)\n"
     ]
    }
   ],
   "source": [
    "new_memory = sum(mem_use2) / 1048576\n",
    "print(\"New memory is \" + \"{:.3f}\".format(new_memory) + \" MB (rounded)\")\n",
    "\n",
    "print(\"Improvment over original: \" + \"{:.4f}\".format((original_memory-new_memory)/original_memory) + \"% (rounded)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**12) [P] Did you notice that to_numeric() has a parameter called downcast? Go back and read about this\n",
    "parameter. By default, most of the time your integer types will be converted to a 64-bit integer, and floating point types will use double precision numbers. You can do far better. Downcast your types accordingly. Report your latest memory usage in MB.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downcast types to less memory usage\n",
    "df_temps.iloc[:,1] = pd.to_numeric(arg=df_temps.iloc[:,1], downcast='integer')\n",
    "for i in range(2, len(df_temps.columns)):\n",
    "    df_temps.iloc[:,i] = pd.to_numeric(arg=df_temps.iloc[:,i], downcast='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New memory is 19.332 MB (rounded)\n",
      "Improvment over original: 0.8574% (rounded)\n"
     ]
    }
   ],
   "source": [
    "#Report latest memory usage\n",
    "new_m2 = sum(df_temps.memory_usage(deep=True)) / 1048576\n",
    "print(\"New memory is \" + \"{:.3f}\".format(new_m2) + \" MB (rounded)\")\n",
    "print(\"Improvment over original: \" + \"{:.4f}\".format((original_memory-new_m2)/original_memory) + \"% (rounded)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**13) At this point, with the exception of the date column, you should have good data to start working with. Verify it\n",
    "by outputting the results of describe(). Every variable should have its basic stats reported!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Observations (n/a)</th>\n",
       "      <th>Average Temp (F)</th>\n",
       "      <th>Max Temp (F)</th>\n",
       "      <th>Min Temp (F)</th>\n",
       "      <th>Average Dewpoint Temp (F)</th>\n",
       "      <th>1 Hour Precip (in)</th>\n",
       "      <th>Max Wind Gust (mph)</th>\n",
       "      <th>Average Relative Humidity (%)</th>\n",
       "      <th>Average Wind Speed (mph)</th>\n",
       "      <th>Average Station Pressure (mb)</th>\n",
       "      <th>Average Wind Direction (deg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>173252.000000</td>\n",
       "      <td>172253.000000</td>\n",
       "      <td>172253.000000</td>\n",
       "      <td>172253.000000</td>\n",
       "      <td>172147.000000</td>\n",
       "      <td>28934.000000</td>\n",
       "      <td>23544.000000</td>\n",
       "      <td>168754.000000</td>\n",
       "      <td>172710.000000</td>\n",
       "      <td>172974.000000</td>\n",
       "      <td>140590.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.339915</td>\n",
       "      <td>51.286217</td>\n",
       "      <td>51.399208</td>\n",
       "      <td>51.179626</td>\n",
       "      <td>40.253628</td>\n",
       "      <td>0.030566</td>\n",
       "      <td>22.295341</td>\n",
       "      <td>68.819511</td>\n",
       "      <td>5.904806</td>\n",
       "      <td>1016.741272</td>\n",
       "      <td>176.806366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.854852</td>\n",
       "      <td>18.888988</td>\n",
       "      <td>18.907930</td>\n",
       "      <td>18.881851</td>\n",
       "      <td>19.053423</td>\n",
       "      <td>0.079247</td>\n",
       "      <td>7.581788</td>\n",
       "      <td>19.694031</td>\n",
       "      <td>5.192565</td>\n",
       "      <td>7.640043</td>\n",
       "      <td>118.790619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-11.900000</td>\n",
       "      <td>-11.900000</td>\n",
       "      <td>-11.900000</td>\n",
       "      <td>-20.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>508.600006</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>25.830000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.600000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1012.200012</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>51.799999</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.900000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>5.370000</td>\n",
       "      <td>1016.900024</td>\n",
       "      <td>220.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>66.900002</td>\n",
       "      <td>66.900002</td>\n",
       "      <td>66.900002</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>26.500000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>1021.700012</td>\n",
       "      <td>280.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>2.350000</td>\n",
       "      <td>88.599998</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>1044.400024</td>\n",
       "      <td>360.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Number of Observations (n/a)  Average Temp (F)   Max Temp (F)  \\\n",
       "count                 173252.000000     172253.000000  172253.000000   \n",
       "mean                       1.339915         51.286217      51.399208   \n",
       "std                        0.854852         18.888988      18.907930   \n",
       "min                        0.000000        -11.900000     -11.900000   \n",
       "25%                        1.000000         36.000000      36.000000   \n",
       "50%                        1.000000         52.000000      52.000000   \n",
       "75%                        1.000000         66.900002      66.900002   \n",
       "max                       10.000000        102.000000     102.000000   \n",
       "\n",
       "        Min Temp (F)  Average Dewpoint Temp (F)  1 Hour Precip (in)  \\\n",
       "count  172253.000000              172147.000000        28934.000000   \n",
       "mean       51.179626                  40.253628            0.030566   \n",
       "std        18.881851                  19.053423            0.079247   \n",
       "min       -11.900000                 -20.900000            0.000000   \n",
       "25%        36.000000                  25.830000            0.000000   \n",
       "50%        51.799999                  41.000000            0.000000   \n",
       "75%        66.900002                  57.000000            0.030000   \n",
       "max       102.000000                  79.000000            2.350000   \n",
       "\n",
       "       Max Wind Gust (mph)  Average Relative Humidity (%)  \\\n",
       "count         23544.000000                  168754.000000   \n",
       "mean             22.295341                      68.819511   \n",
       "std               7.581788                      19.694031   \n",
       "min               0.000000                       0.000000   \n",
       "25%              19.600000                      54.000000   \n",
       "50%              21.900000                      71.000000   \n",
       "75%              26.500000                      86.000000   \n",
       "max              88.599998                     100.000000   \n",
       "\n",
       "       Average Wind Speed (mph)  Average Station Pressure (mb)  \\\n",
       "count             172710.000000                  172974.000000   \n",
       "mean                   5.904806                    1016.741272   \n",
       "std                    5.192565                       7.640043   \n",
       "min                    0.000000                     508.600006   \n",
       "25%                    0.000000                    1012.200012   \n",
       "50%                    5.370000                    1016.900024   \n",
       "75%                    9.200000                    1021.700012   \n",
       "max                   76.000000                    1044.400024   \n",
       "\n",
       "       Average Wind Direction (deg)  \n",
       "count                 140590.000000  \n",
       "mean                     176.806366  \n",
       "std                      118.790619  \n",
       "min                        0.000000  \n",
       "25%                       70.000000  \n",
       "50%                      220.000000  \n",
       "75%                      280.000000  \n",
       "max                      360.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temps.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Transformation with Dates (a lot of text, see lab)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**14) [M] There are four primary classes in pandas for working with dates and times? Consider the Scalar Class for\n",
    "each, and state what concept each is representing.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Timestamp    Concept: date times- a specific date and time with timezone support\n",
    "#### 2. Timedelta      Concept: time deltas- an absolute time duration\n",
    "#### 3. Period            Concept: time spans- a span of time defined by a point in time and its associate frequency\n",
    "####  4. DateOffset    Concept: date offsets- a relative time duration that respect calendar arithmetic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**15) [M] For each above, state the primary creation method used to create each type of data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timestamp: to_datetime or date_range\n",
    "#### Timedelta: to_timedelta or timedelta_range\n",
    "#### Time spans: Period or period_range\n",
    "#### DateOffset: Dateoffset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**16) [P] Create a Timestamp object from the string \"07/04/19\", which is a date representing July 4, 2019.\n",
    "Store the object as d1 and show it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-07-04 00:00:00')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = pd.to_datetime(\"07/04/19\")\n",
    "d1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**17) [P] Using d1 and string formatting codes, print the string from d1:\n",
    "\"Today's date is Thursday, July 4, 2019\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today's date is Thursday, July 4, 2019\n"
     ]
    }
   ],
   "source": [
    "#I don't know if this is what you wanted...\n",
    "print(\"Today's date is \" + d1.day_name() + \", \" + d1.month_name() + \" \" + str(d1.day) + \", \" + str(d1.year))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**18) [P] Create another Timestamp object representing Sept 7, 2019 at 3pm, called d2. Report it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-09-07 15:00:00')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2 = pd.to_datetime(\"09/07/19 15:00:00\")\n",
    "d2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**19) [P] Subtract d2 – d1, and report the difference as the number of days and seconds between these two. Also\n",
    "report the difference as total seconds. (NOTE: The difference should be 65 days, 54000 seconds. Or 5670000\n",
    "total seconds.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference is 65 days and 54000 seconds.\n",
      "Total seconds is 5670000.0\n"
     ]
    }
   ],
   "source": [
    "d19 = d2 - d1 #Implicitly creates a timedelta object\n",
    "print(\"Difference is \" + str(d19.days) + \" days and \" + str(d19.seconds) + \" seconds.\")\n",
    "print(\"Total seconds is \" + str(d19.total_seconds()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**20) [P] Create a new Timestamp object from the string \"2019-07-01 08:30pm\", but, localize the time\n",
    "stamp to represent the time in the US Eastern Time Zone. Store the result as d3 and output it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-07-01 20:30:00-0400', tz='US/Eastern')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d3 = pd.to_datetime(\"2019-07-01 08:30pm\").tz_localize(\"US/Eastern\")\n",
    "d3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**21) [P] Show time represented by d3, but converted to the US / Pacific Time Zone. The time reported should be\n",
    "three hours earlier than EST shown in the previous question.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-07-01 17:30:00-0700', tz='US/Pacific')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d3.tz_convert(\"US/Pacific\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**22) [P] Create a Timestamp object representing right now, stored as ts_now. Show the result.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-02-04 21:28:52.720375')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_now = pd.Timestamp.now()\n",
    "ts_now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**23) [P] Create a Timedelta object representing 1 hour, stored as td_hour. Show the result.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('0 days 01:00:00')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td_hour = pd.Timedelta(hours=1)\n",
    "td_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**24) [P] Demonstrate how you can do basic mathematical operations by adding 6 hours to ts_now using\n",
    "td_hour and basic math operations. (i.e. No loops or further calculations necessary!)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-02-05 03:28:52.720375')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_now + 6*td_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**25) [P] Create a DatetimeIndex object that represents every hour during the month of January, 2019. The first\n",
    "index should be midnight, January 1, 2020, and the last index should be January 31, 2020 at 11pm. Store the\n",
    "object as dr. (HINT – use the pd.date_range() method!)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr = pd.date_range(start=pd.to_datetime(\"01/01/2020 00:00:00\"), end=pd.to_datetime(\"01/31/2020 23:00:00\"), freq=\"H\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OK, so that was a little practice with understanding how to work a bit with dates and times. They are objects, with\n",
    "lots of methods to help you access those timestamps in different ways.\n",
    "Back to our weather data. Usually, the index to a dataframe represents the data you will use most often to access\n",
    "and select your data. In the case of a time series dataset, the index is usually the time. In other words, every\n",
    "observation should be indexed by a Timestamp object! You'll make that happen next...**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**26) [P] The first variable in our data is currently an object. But, notice the name and its units? It's a date/time in\n",
    "the GMT time zone! Convert the first column of data into an actual time stamp.\n",
    "NOTE: You can NOT simply generate this column using your own date range object! You must generate it\n",
    "directly from the actual time/date stamp in the data! Why? This is very important. Do NOT ever be fooled\n",
    "into thinking any real-world dataset you are dealing with is 100% complete. There are missing observations\n",
    "in these data, and your data will be massively flawed if you neglect this! If you simply try to use a date range\n",
    "between 1/1 – 12/31, with every hour, you are making an incorrect assumption that every observation is\n",
    "present.\n",
    "(HINT: Go back to your reference table. You are creating an array of timestamps. Which function? Either\n",
    "to_datetime or date_range. We already told you that date_range is wrong!)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pd.to_datetime() on first column of df_temps\n",
    "df_temps.iloc[:,0] = pd.to_datetime(df_temps.iloc[:,0])#.convert(\"US/GMT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**27) [P] Confirm that your first column data type is now a timestamp by showing the output of\n",
    "df_temps.info(). (It should show that it is datetime64, to be exact) . Then, show the values of the\n",
    "first column of the first AND last row only. Your result should look like:\n",
    "0 2000-01-01 00:00:00\n",
    "173251 2019-12-31 23:00:00**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 173252 entries, 0 to 173251\n",
      "Data columns (total 12 columns):\n",
      "Date/Time (GMT)                  173252 non-null datetime64[ns]\n",
      "Number of Observations (n/a)     173252 non-null int8\n",
      "Average Temp (F)                 172253 non-null float32\n",
      "Max Temp (F)                     172253 non-null float32\n",
      "Min Temp (F)                     172253 non-null float32\n",
      "Average Dewpoint Temp (F)        172147 non-null float32\n",
      "1 Hour Precip (in)               28934 non-null float32\n",
      "Max Wind Gust (mph)              23544 non-null float32\n",
      "Average Relative Humidity (%)    168754 non-null float32\n",
      "Average Wind Speed (mph)         172710 non-null float32\n",
      "Average Station Pressure (mb)    172974 non-null float32\n",
      "Average Wind Direction (deg)     140590 non-null float32\n",
      "dtypes: datetime64[ns](1), float32(10), int8(1)\n",
      "memory usage: 8.1 MB\n"
     ]
    }
   ],
   "source": [
    "df_temps.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2000-01-01 00:00:00\n",
       "173251   2019-12-31 23:00:00\n",
       "Name: Date/Time (GMT), dtype: datetime64[ns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temps.iloc[[0,-1],0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**28) Finally, let's move that first column to be the new index for your dataframe. Use the set_index method of\n",
    "of df_temps to be the first column of data, then use the drop method to eliminate the first column. It is now your index, and thus there is no need to keep this information twice.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temps = df_temps.set_index(df_temps.columns[0]) #drop=True by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**29) [P] Give one final report on the total memory usage, and also show the % memory reduction made compared\n",
    "to when you first loaded the data.\n",
    "Again, please take this seriously. This is a substantial amount of memory saved! Why? Because you took the\n",
    "time to properly process every column to have it represent its most accurate type, using the smallest type\n",
    "necessary. HUGE savings!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New memory is 8.096 MB (rounded)\n",
      "Improvment over original: 0.9403% (rounded)\n"
     ]
    }
   ],
   "source": [
    "new_m29 = sum(df_temps.memory_usage(deep=True)) / 1048576\n",
    "print(\"New memory is \" + \"{:.3f}\".format(new_m29) + \" MB (rounded)\")\n",
    "print(\"Improvment over original: \" + \"{:.4f}\".format((original_memory-new_m29)/original_memory) + \"% (rounded)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**30) [P] This dataset has missing observations. But, how many? First, calculate how many observations SHOULD be\n",
    "there. Use the difference between the first and last index value to compute this.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There should be 175319.0 observations total\n",
      "There are 2068.0 missing\n"
     ]
    }
   ],
   "source": [
    "d30 = df_temps.index[-1] - df_temps.index[0]\n",
    "d31 = d30.total_seconds() / 3600\n",
    "print(\"There should be \" + str(d31) + \" observations total\")\n",
    "print(\"There are \" + str(d31 - 173251) + \" missing\") # Number is length of df_temps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**31) [P] There are quite a lot! It's time to investigate. Create a data frame called df_missing that has an index\n",
    "of the time stamp of every missing date, with a simple variable called \"missing\" that has a value of 1 for every\n",
    "entry. (i.e. it should only contain the missing dates.) Report the number of rows in df_missing. It should\n",
    "match the number you computed previously.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in df_missing: 2068\n"
     ]
    }
   ],
   "source": [
    "missing_dates = pd.date_range(start=df_temps.index[0], end=df_temps.index[-1], freq=\"H\").difference(df_temps.index)\n",
    "\n",
    "one_series = pd.Series(np.ones(len(missing_dates)), index=missing_dates, name=\"missing\")\n",
    "d = {'missing':one_series}\n",
    "df_missing = pd.DataFrame(data=d)\n",
    "print(\"Number of rows in df_missing: \" + str(df_missing.shape[0])) #This is how many missing dates there were"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**32) [P] Let's get a sense of which years seem to be missing the most data. How? Well, the easiest approach is\n",
    "probably to use the resample() method of data frames. Check out this section:\n",
    "https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#resampling . This method works\n",
    "phenomenally well for grouping and aggregating your data when you have a datetime index type!\n",
    "We're going to resample our data by year, and perform a count aggregation all in one line:\n",
    "Enter the following:\n",
    "df_missing_by_year = df_missing.resample('Y').count()\n",
    "There are many, many ways you can resample your data. You need to jump over to the options for dateoffset\n",
    "objects. The letter codes are specified there:\n",
    "https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects\n",
    "Show the result of df_missing_by_year**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-12-31</th>\n",
       "      <td>792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-12-31</th>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-12-31</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-12-31</th>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-12-31</th>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-31</th>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-31</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-31</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-12-31</th>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-12-31</th>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-12-31</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-31</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-31</th>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-31</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-31</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-31</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31</th>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            missing\n",
       "2000-12-31      792\n",
       "2001-12-31       54\n",
       "2002-12-31       30\n",
       "2003-12-31       39\n",
       "2004-12-31       72\n",
       "2005-12-31      119\n",
       "2006-12-31       32\n",
       "2007-12-31       64\n",
       "2008-12-31      193\n",
       "2009-12-31       82\n",
       "2010-12-31       40\n",
       "2011-12-31       32\n",
       "2012-12-31      152\n",
       "2013-12-31       45\n",
       "2014-12-31       38\n",
       "2015-12-31       37\n",
       "2016-12-31       27\n",
       "2017-12-31      119\n",
       "2018-12-31       67\n",
       "2019-12-31       34"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_missing_by_year = df_missing.resample('Y').count()\n",
    "df_missing_by_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**33) [P] You can see that pretty much every year has missing data. Not uncommon. However, one year in particular\n",
    "is really bad. Which one? Write the code to eliminate that entire year from df_temps.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Observations (n/a)</th>\n",
       "      <th>Average Temp (F)</th>\n",
       "      <th>Max Temp (F)</th>\n",
       "      <th>Min Temp (F)</th>\n",
       "      <th>Average Dewpoint Temp (F)</th>\n",
       "      <th>1 Hour Precip (in)</th>\n",
       "      <th>Max Wind Gust (mph)</th>\n",
       "      <th>Average Relative Humidity (%)</th>\n",
       "      <th>Average Wind Speed (mph)</th>\n",
       "      <th>Average Station Pressure (mb)</th>\n",
       "      <th>Average Wind Direction (deg)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date/Time (GMT)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001-01-01 00:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>1019.000000</td>\n",
       "      <td>270.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01 01:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>19.9</td>\n",
       "      <td>19.9</td>\n",
       "      <td>19.9</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>1019.000000</td>\n",
       "      <td>270.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01 02:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.0</td>\n",
       "      <td>16.1</td>\n",
       "      <td>1019.000000</td>\n",
       "      <td>270.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01 03:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1018.599976</td>\n",
       "      <td>260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01 04:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.0</td>\n",
       "      <td>16.1</td>\n",
       "      <td>1018.599976</td>\n",
       "      <td>280.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Number of Observations (n/a)  Average Temp (F)  \\\n",
       "Date/Time (GMT)                                                       \n",
       "2001-01-01 00:00:00                             1              21.0   \n",
       "2001-01-01 01:00:00                             1              19.9   \n",
       "2001-01-01 02:00:00                             1              19.0   \n",
       "2001-01-01 03:00:00                             1              19.0   \n",
       "2001-01-01 04:00:00                             1              19.0   \n",
       "\n",
       "                     Max Temp (F)  Min Temp (F)  Average Dewpoint Temp (F)  \\\n",
       "Date/Time (GMT)                                                              \n",
       "2001-01-01 00:00:00          21.0          21.0                        6.1   \n",
       "2001-01-01 01:00:00          19.9          19.9                        7.0   \n",
       "2001-01-01 02:00:00          19.0          19.0                        7.0   \n",
       "2001-01-01 03:00:00          19.0          19.0                        7.0   \n",
       "2001-01-01 04:00:00          19.0          19.0                        6.1   \n",
       "\n",
       "                     1 Hour Precip (in)  Max Wind Gust (mph)  \\\n",
       "Date/Time (GMT)                                                \n",
       "2001-01-01 00:00:00                 NaN                  NaN   \n",
       "2001-01-01 01:00:00                 NaN                  NaN   \n",
       "2001-01-01 02:00:00                 NaN                  NaN   \n",
       "2001-01-01 03:00:00                 NaN                  NaN   \n",
       "2001-01-01 04:00:00                 NaN                  NaN   \n",
       "\n",
       "                     Average Relative Humidity (%)  Average Wind Speed (mph)  \\\n",
       "Date/Time (GMT)                                                                \n",
       "2001-01-01 00:00:00                           51.0                      12.7   \n",
       "2001-01-01 01:00:00                           56.0                      10.4   \n",
       "2001-01-01 02:00:00                           58.0                      16.1   \n",
       "2001-01-01 03:00:00                           58.0                      15.0   \n",
       "2001-01-01 04:00:00                           56.0                      16.1   \n",
       "\n",
       "                     Average Station Pressure (mb)  \\\n",
       "Date/Time (GMT)                                      \n",
       "2001-01-01 00:00:00                    1019.000000   \n",
       "2001-01-01 01:00:00                    1019.000000   \n",
       "2001-01-01 02:00:00                    1019.000000   \n",
       "2001-01-01 03:00:00                    1018.599976   \n",
       "2001-01-01 04:00:00                    1018.599976   \n",
       "\n",
       "                     Average Wind Direction (deg)  \n",
       "Date/Time (GMT)                                    \n",
       "2001-01-01 00:00:00                         270.0  \n",
       "2001-01-01 01:00:00                         270.0  \n",
       "2001-01-01 02:00:00                         270.0  \n",
       "2001-01-01 03:00:00                         260.0  \n",
       "2001-01-01 04:00:00                         280.0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This was surprisingly easy\n",
    "bad_year = df_missing_by_year.idxmax()[0].year\n",
    "df_temps = df_temps[df_temps.index.year != bad_year]\n",
    "df_temps.head() #Starts in 2001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
