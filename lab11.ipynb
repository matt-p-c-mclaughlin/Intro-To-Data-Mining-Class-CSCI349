{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab11 - Keras\n",
    "#### Name - Matt McLaughlin\n",
    "#### Class - CSCI349 \n",
    "#### Instructor - Brian King"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) What is an artificial neural network (ANN)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) What is deep learning? How does it relate to an ANN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Name a couple of examples where deep learning has made a tremendous impact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Briefly, what is the feedforward algorithm with a neural net?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) In the context of machine learning, what is a loss function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) What is gradient descent? And how is the loss function a critical part of gradient descent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Training a neural net involves the backpropagation algorithm. In a few sentences, describe what this algorithm does."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) What is the difference between batch gradient descent and stochastic gradient descent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) In the context of neural network training, explain the terms epoch and batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) In the context of machine learning, what is a hyperparameter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11) In the context of neural nets training, what are examples of hyperparameters that can affect model performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12) What is an activation function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13) Most agree that the most popular activation functions are sigmoid, hyperbolic tangent (tanh), softmax, and-ReLu (rectified linear unit). Compare and contrast each, using whatever resources you want. Again, 1-2 sentences for each Is sufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14) Why is ReLu so popular for large, deep learning networks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15) Why is softmax most appropriate for the output layer, especially for classification problems?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16) What does ReLu sometimes suffer from, and how does a Leaky ReLu activation address it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next few questions are focused around Keras and Tensorflow:\n",
    "17) What is Tensorflow? Who created it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18) What are tensors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19) What is keras? Who created it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20) Explain the relationship between keras and tensorflow. How are they similar? Different?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining questions all pertain specifically to specific classes or critical methods in Keras. Most of these you\n",
    "can get directly from the Keras documentation. https://keras.io/\n",
    "21) Describe what the Sequential class represents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22) What is a layer? How is a layer added to a model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23) What is a Dense layer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "24) What does the compile method do for a model, and what two parameters are required to compile every model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) [P] Copy over your code from the previous lab that read in and pre-processed the iris dataset from\n",
    "seaborn. You should have a pandas dataframe that contains four numeric variables and one categorical\n",
    "variable representing the target class. You should have one dataframe X and a dataframe y representing\n",
    "the target class. Do not split your data into training and testing data yet.\n",
    "NORMALLY, I would always expect some EDA tasks to be performed to understand the distributions of your\n",
    "data (i.e. the center, shape, spread of your variables, etc). However, you did a lot of that in the previous lab.\n",
    "Generally, these variables have very similar distributions, with centers that are near each other. Thus,\n",
    "technically, you really don't need to standardize your variables. However, for most models we've learned\n",
    "about, it's a good idea. So, if you did not standardize, go ahead and do that to your X dataframe now using a\n",
    "z-score standardization. (All variables are numeric, so this is quite straightforward.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) [P] Shuffle your data in your data frames. This will be important for later exercises. Read about the\n",
    "shuffle() function in sklearn.utils. Import it, and use it to shuffle your X and y data frames. Use\n",
    "random_state=0. Remember â€“ it returns the shuffled data! So, be sure to reassign X and y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) [P] Use train_test_split to split your data, but this time, let's use an even smaller split, using a 50/50\n",
    "split, initializing with a random state of 0. (Why? This is a relatively simple dataset. Let's make the problem a\n",
    "bit more challenging by introducing a smaller training data size.)\n",
    "Completing this will result in X_train, X_test, y_train and y_test data frames, both with 75\n",
    "instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) [M] How many inputs will your network need to have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) [M] Consider the outputs required for a neural network. Remember that the iris dataset is a multi-class\n",
    "dataset. It has to predict three different, categorical values. How do you represent a multi-class target\n",
    "variable in a model like a neural net? For the iris data, what does the final layer of your neural net\n",
    "structure need to look like?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) [P] Write the code to convert the iris target variables (i.e. y_train and y_test) to a set of binarized\n",
    "variables derived from the target class variable (why? Hopefully you figured out why based on your previous\n",
    "answer!)\n",
    "With iris, this means that the \"species\" variable should be converted to a data frame (or numpy\n",
    "array) of three variables, one representing each species. (HINT: as usual, there are many ways to do this. I\n",
    "like pandas get_dummies() or scikit-learn's OneHotEncoder.)\n",
    "OK. You are now going to build a very basic ANN structure with only one hidden layer. Feel free to explore more\n",
    "complex structures, just for practice, but for this simple dataset, you won't need it. For this first exercise, I'll step\n",
    "you through the basics, but you are encouraged to document the &#^!%$ out of each line, as you want to work\n",
    "toward a solid understanding of what you are doing here! Don't just blindly copy and paste what you see online. If\n",
    "you don't document and understand, you will NOT have the guidance and confidence to work through the next\n",
    "assignment. It will be far more challenging.\n",
    "Each line tells you to complete a task. The process is laid out exhaustively to ensure that you understand every\n",
    "critical step toward building the structure of a neural net, train it, and then use it. (HINT: As stated above, be sure\n",
    "to open a page to the Keras documentation referred to above!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Create an instance of Sequential() called model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Now, we will sequentially add layers, starting with the hidden layer that receives the input, then you\n",
    "continue adding layers until you get to the output layer. We will keep it simple: one hidden layer, and one\n",
    "output layer.\n",
    "Add a Dense layer representing the hidden layer. The first layer you add always needs to specify the\n",
    "number of inputs. And, you also need to specify the number of units in the layer (e.g. 9-12 is a good start for\n",
    "these simple data.) Specify an activation function of your choosing. Most basic nets use a 'sigmoid' or\n",
    "'tanh' activation, though deep learning emphasizes 'relu'. (Be sure you understand why at some point\n",
    "in your near future!) Any of the above is fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) Add one more layer representing the output layer. Be sure to specify the correct number of outputs.\n",
    "Remember, use a 'softmax' activation here. (NOTE â€“ after you specify your first layer, the number of\n",
    "inputs in further layers added are implied, and thus do not need to be specified.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) OK. Now compile your model. Look at the documentation for the compile() method. You'll need to\n",
    "specify the following parameters:\n",
    "a) Choose an optimizer â€“ This is a GREATLY HEATED TOPIC on deep learning and ANN blogs. The facts:\n",
    "Stochastic Gradient Descent (SGD) is the quintessential standard. It is the basis of neural net learning. It\n",
    "is mathematically sound, though it can suffer from the worst computational performance (i.e. timing to\n",
    "convergence.) All enhancements and newer methods are based on SGD. For SGD, an appropriate\n",
    "selection a momentum parameter makes a huge difference, and papers have come out demonstrating\n",
    "that SGD + a good momentum parameter are as effective as the most hyped optimization techniques, if\n",
    "you can identify good parameters. (For example: https://arxiv.org/abs/1705.08292 ) Selecting good\n",
    "learning rates, momentum and other parameters is not easy. Theoretically, there are an infinite number\n",
    "of combinations you could choose. So, several other methods have come out to help address the\n",
    "challenges of selecting good parameters. Adam is most commonly used optimizer in practice for deep\n",
    "learning. So, use optimizer='sgd' to start, but then go back and set it to optimizer = 'adam'.\n",
    "b) Choose the loss function â€“ This is the function that gives you the error that is backpropagated. Use\n",
    "loss='categorical_crossentropy' for this problem.\n",
    "c) Choose the performance metrics â€“ Typically, you will stick with metrics=['accuracy'] here. You\n",
    "can do far more with your predictions later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11) OK, your structure is set. Now you need to train the model. Look at the documentation for the fit()\n",
    "method. Use fit to train your model with X_train and your binarized y_train data. There are many\n",
    "additional parameters available that basically control how you perform weight updates. This is where,\n",
    "depending on your data size and your selection of parameters, you could be waiting a while. This is a SIMPLE\n",
    "dataset, and should take no more than a 5-10 seconds to get good results.\n",
    "You can start with the following:\n",
    "a) epochs = number of epochs to train the model. An epoch is an iteration over all your training data. You\n",
    "will need to experiment. Start with a value of 100.\n",
    "b) batch_size = number of samples per gradient update. Updating every instance will usually converge\n",
    "the earliest, but with high variance. At the other extreme, batch_size using the entire dataset is slow, but\n",
    "very smooth convergence. Experiment. Use 1, 5, 15. You'll need to select the number of epochs in\n",
    "conjunction with this parameter. For this simple problem, batch_size = 1 will likely work just fine.\n",
    "c) verbose = 1 will show output as training progresses. Very useful!\n",
    "d) Use validation_data to pass your test data. This will make it easy to understand if your model is\n",
    "overfitting your data. (This slows things down a bit more, but it's so important to capture how your model\n",
    "is doing on BOTH training and test data!)\n",
    "The fit() method returns a History object. Look up what this is, and store this result! You'll use it in the\n",
    "next step!\n",
    "Congratulations! You have a trained keras model!\n",
    "Take a moment, and think about the vast number of different parameters that influence the model that is\n",
    "built. Certainly, the structure of the network itself has a substantial influence. But think about the\n",
    "hyperparameters. There are many. This is a challenging problem with deep learning models, especially\n",
    "because the problem of performing a search for optimal parameters is nearly impossible. The best you\n",
    "can hope to do is use some type of framework to make hyperparameter tuning a bit easier. (This is\n",
    "coming up in the next lab.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12) [P] It's important to understand your accuracy and loss rates as your model proceeds through training.\n",
    "Visualize the loss on training and test data. Look at the code presented here: https://keras.io/visualization/.\n",
    "You may copy it, or make it more fancy if you choose to do so. Pay attention to the section of code that\n",
    "shows Training history visualization. You may also include the code that visualizes the model, as it may be\n",
    "good to know for your future.\n",
    "If you did everything correctly, you should show two graphs, one for model loss, and one for model\n",
    "accuracy.\n",
    "Below are my example graphs, based on the code given on the Keras documentation page. I used 'adam'\n",
    "for optimization, a single hidden layer with 12 units, and 'sigmoid' activation. I trained with\n",
    "epochs=100, and batch_size=1. You'll see that these parameters do pretty well for these data. Even\n",
    "the test data performs quite well.\n",
    "\n",
    "You can see how useful these plots are. Both loss curves are only starting to stabilize! This suggests that it\n",
    "may be worth repeating this with 150 epochs? Or, do we reduce the number of hidden units? Change the\n",
    "optimization? The momentum? Argh! There are so many parameters that can influence getting the best\n",
    "model!\n",
    "I shouldn't be telling you this. But, in case you haven't, you should be moving code like this into functions\n",
    "that you can reuse..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13) Try to change some parameters with the model. However, instead of copying and pasting each individual\n",
    "line you wrote above, follow the approach of creating the entire structure in a single line. Use the example\n",
    "laid out in the Keras documention https://keras.io/getting-started/sequential-model-guide/ This will get\n",
    "you started:\n",
    "model = Sequential([\n",
    "Dense(12, input_shape=(4,)),\n",
    "Activation( ??? ),\n",
    "...\n",
    "])\n",
    "\n",
    "Clearly, you need to finish the rest. And, you'll need to compile and build your model. However, change the\n",
    "parameters in some way from what you did above. Clearly, as given above, you need 4 inputs, and 3\n",
    "outputs. Beyond that, you have countless ways to create a different approach! Different structure? An\n",
    "additional hidden layer? Different activation? Or, use the same structure, and use different batch_size for\n",
    "training? Different optimization algorithm? More epochs? Etc. The choices are quite vast!\n",
    "Generate the same two plots. Compare and contrast your findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14) OK, one more time. This time, copy the same model, but use an SGD optimizer. Of course, you may have\n",
    "already chosen this by specifying the optimizer='sgd' parameter when you compiled your model. This\n",
    "time, you will instantiate your optimizer.\n",
    "From Keras documentation:\n",
    "\n",
    "Copy one of your models above. (Remember, if you keep using the same model instance, you are\n",
    "continually improving the weights, and thus not evaluating your new model properly! When you\n",
    "experiment with new models, you need to instantiate a new model, or figure out how to reset your\n",
    "weights to random initial values. For now, it's just easy enough to reinstantiate a new model.)\n",
    "Now, instantiate SGD. Look at the documentation, and choose a different learning rate (lr) and a\n",
    "momentum value of some value between 0.5-0.9. Compile and fit your model. Regenerate your accuracy\n",
    "and loss plots. Compare and contrast your findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15) Remember, this is a classification problem. Use your model to predict the classes for the test data (using the\n",
    "function predict_classes), and store the results as y_pred."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16) Finally, using your code from the lab on classification, output the confusion_matrix and the\n",
    "classification_report (from scikit-learn's metric package) to print out the complete\n",
    "performance results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
